# Guia de Testes - Flask Todo App

Este documento explica como executar e entender os testes unitÃ¡rios e de integraÃ§Ã£o da aplicaÃ§Ã£o Flask Todo.

## ğŸ“‹ Ãndice

- [InstalaÃ§Ã£o das DependÃªncias](#instalaÃ§Ã£o-das-dependÃªncias)
- [Estrutura dos Testes](#estrutura-dos-testes)
- [Como Executar os Testes](#como-executar-os-testes)
- [Tipos de Teste](#tipos-de-teste)
- [Cobertura de CÃ³digo](#cobertura-de-cÃ³digo)
- [Interpretando os Resultados](#interpretando-os-resultados)

## ğŸš€ InstalaÃ§Ã£o das DependÃªncias

Primeiro, instale todas as dependÃªncias necessÃ¡rias:

```bash
pip install -r requirements.txt
```

## ğŸ“ Estrutura dos Testes

```
python-flask-app-test/
â”œâ”€â”€ app.py              # AplicaÃ§Ã£o principal
â”œâ”€â”€ app_test.py         # Arquivo principal de testes
â”œâ”€â”€ run_tests.py        # Script para executar testes
â”œâ”€â”€ pytest.ini         # ConfiguraÃ§Ã£o do pytest
â”œâ”€â”€ requirements.txt    # DependÃªncias (incluindo pytest)
â””â”€â”€ TESTING.md         # Este documento
```

## ğŸ§ª Como Executar os Testes

### OpÃ§Ã£o 1: Usando o script personalizado (Recomendado)

```bash
# Executar todos os testes
python run_tests.py --all

# Executar apenas testes unitÃ¡rios
python run_tests.py --unit

# Executar apenas testes de integraÃ§Ã£o
python run_tests.py --integration

# Executar com relatÃ³rio de cobertura
python run_tests.py --coverage

# Executar com saÃ­da detalhada
python run_tests.py --verbose

# Incluir testes lentos
python run_tests.py --slow
```

### OpÃ§Ã£o 2: Usando pytest diretamente

```bash
# Todos os testes
pytest app_test.py

# Testes com verbose
pytest -v app_test.py

# Apenas testes unitÃ¡rios
pytest -m unit app_test.py

# Apenas testes de integraÃ§Ã£o
pytest -m integration app_test.py

# Testes com cobertura
pytest --cov=app --cov-report=html app_test.py
```

## ğŸ¯ Tipos de Teste

### 1. Testes UnitÃ¡rios (`@pytest.mark.unit`)

Testam componentes individuais isoladamente:

- **TestTodoModel**: Testa o modelo Todo
  - `test_todo_creation()`: CriaÃ§Ã£o de instÃ¢ncias
  - `test_todo_repr()`: RepresentaÃ§Ã£o string
  - `test_todo_database_save()`: Salvamento no banco

### 2. Testes de IntegraÃ§Ã£o (`@pytest.mark.integration`)

Testam a interaÃ§Ã£o entre componentes:

- **TestRoutes**: Testa as rotas da aplicaÃ§Ã£o
  - `test_index_get_empty()`: PÃ¡gina inicial vazia
  - `test_index_get_with_tasks()`: PÃ¡gina com tarefas
  - `test_index_post_valid_data()`: CriaÃ§Ã£o via POST
  - `test_delete_existing_task()`: ExclusÃ£o de tarefa
  - `test_update_post_existing_task()`: AtualizaÃ§Ã£o de tarefa

### 3. Testes de Erro (`TestErrorScenarios`)

Testam cenÃ¡rios de falha:

- `test_index_post_database_error()`: Erro ao criar tarefa
- `test_delete_database_error()`: Erro ao deletar tarefa
- `test_update_database_error()`: Erro ao atualizar tarefa

### 4. Testes de Performance (`@pytest.mark.slow`)

Testam performance e comportamento em larga escala:

- `test_multiple_tasks_creation()`: CriaÃ§Ã£o de 100 tarefas
- `test_task_ordering()`: VerificaÃ§Ã£o de ordenaÃ§Ã£o

## ğŸ“Š Cobertura de CÃ³digo

Para gerar relatÃ³rio de cobertura:

```bash
python run_tests.py --coverage
```

Isso gerarÃ¡:
- RelatÃ³rio no terminal mostrando linhas nÃ£o cobertas
- Arquivo HTML em `htmlcov/index.html` para visualizaÃ§Ã£o detalhada

### Interpretando a Cobertura

- **Verde**: Linhas cobertas pelos testes
- **Vermelho**: Linhas nÃ£o cobertas
- **Amarelo**: Linhas parcialmente cobertas

## ğŸ” Interpretando os Resultados

### Exemplo de SaÃ­da Bem-Sucedida

```
=================== test session starts ===================
collected 15 items

app_test.py::TestTodoModel::test_todo_creation PASSED     [ 6%]
app_test.py::TestTodoModel::test_todo_repr PASSED         [13%]
app_test.py::TestRoutes::test_index_get_empty PASSED      [20%]
...
=================== 15 passed in 2.34s ===================
```

### Exemplo de Falha

```
=================== FAILURES ===================
____ TestTodoModel.test_todo_creation ____

    def test_todo_creation(self, client):
>       assert todo.content == "Nova tarefa"
E       AssertionError: assert None == "Nova tarefa"

app_test.py:52: AssertionError
```

## ğŸ›ï¸ Fixtures Utilizadas

### `client`
- Cria um cliente de teste com banco de dados temporÃ¡rio
- Limpa automaticamente apÃ³s cada teste
- Usado em praticamente todos os testes

### `sample_todo`
- Cria uma tarefa de exemplo para reutilizaÃ§Ã£o
- Ãštil para testes que precisam de dados prÃ©-definidos

## ğŸš¨ Mocks e SimulaÃ§Ãµes

Os testes usam `unittest.mock` para simular:

- **Falhas de banco de dados**: Simulando exceÃ§Ãµes nas operaÃ§Ãµes
- **Isolamento**: Testando componentes sem dependÃªncias externas

Exemplo:
```python
@patch('app.db.session.commit')
def test_database_error(self, mock_commit, client):
    mock_commit.side_effect = Exception("Database error")
    # Teste continua...
```

## ğŸ”§ ConfiguraÃ§Ã£o Personalizada

### pytest.ini

ConfiguraÃ§Ãµes globais do pytest:

```ini
[tool:pytest]
testpaths = .
python_files = *_test.py test_*.py
python_classes = Test*
python_functions = test_*
addopts = -v --tb=short --strict-markers
```

## ğŸ“ˆ Melhores PrÃ¡ticas Implementadas

1. **Isolamento**: Cada teste usa um banco de dados limpo
2. **Nomenclatura clara**: Nomes de teste descritivos
3. **DocumentaÃ§Ã£o**: Docstrings explicando o propÃ³sito
4. **OrganizaÃ§Ã£o**: Testes agrupados em classes por funcionalidade
5. **Marcadores**: SeparaÃ§Ã£o entre unit, integration e slow tests
6. **Cleanup**: Limpeza automÃ¡tica de recursos

## ğŸ†˜ Troubleshooting

### Erro: "No module named 'app'"

```bash
# Certifique-se de estar no diretÃ³rio correto
cd /home/azaf/testing/python/python-flask-app-test
python -m pytest app_test.py
```

### Erro: "Database locked"

```bash
# Remova arquivos de banco temporÃ¡rios
rm -f test.db*
rm -f *.db*
```

### Erro: DependÃªncias nÃ£o encontradas

```bash
# Reinstale as dependÃªncias
pip install -r requirements.txt
```

## ğŸ¯ PrÃ³ximos Passos

Para melhorar ainda mais os testes:

1. **Testes de API**: Testar endpoints JSON se existirem
2. **Testes de SeguranÃ§a**: Verificar proteÃ§Ãµes CSRF, XSS
3. **Testes de Carga**: Usar ferramentas como locust
4. **Testes E2E**: Selenium para testes de interface
5. **CI/CD**: IntegraÃ§Ã£o com GitHub Actions

---

**ğŸ’¡ Dica**: Execute `python run_tests.py --coverage` regularmente para manter boa cobertura de testes!